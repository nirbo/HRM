Make TransformerEngine optional and add helper script for FP8 setup.

Summary of changes:
- Updated transformer layers to catch any TransformerEngine import failure and emit a runtime warning instead of crashing; BF16 runs continue unaffected.
- Trainer now persists the effective mixed-precision mode back into the config and disables the fp8 block whenever FP8 isnâ€™t requested, keeping configs consistent.
- Added `scripts/install_transformer_engine.sh` to set cuDNN include/lib paths and reinstall TransformerEngine quickly after installing the cuDNN wheel.

Testing & validation:
- `python -m compileall src/hrm_lm/training/train.py src/hrm_lm/models/transformer_layers.py scripts/install_transformer_engine.sh`

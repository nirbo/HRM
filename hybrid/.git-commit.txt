Add HRM warmup controls and trainer stability docs

- extend training CLI with patience grace, HRM gate warmup, and LR floor options and wire runtime behavior into warmup, scheduler, and early-stop logic
- add gate_scale buffer to HRM hybrid model so curricula can stage decoder conditioning without touching bridge internals
- document new trainer flags in TRAINING.md and note warmup/lr-floor usage for large runs
- record session updates in llm.state for reproducibility and include tokenizer.json artifact required for fresh training runs

Add batch size override for trainer

Summary
- Introduced `--batch_size` CLI flag that supersedes config batch size for training/validation batches.
- Updated documentation to show new usage and clarified that grad accumulation is not yet configurable.
- Verified via dry-run with custom batch size, full synthetic run, and pytest.

Files
- src/hrm_lm/training/train.py — batch-size override logic and CLI flag.
- TRAINING.md — refreshed examples and CLI table entry.
- llm.state — updated log (unincluded).

Title: Copy tokenizer artifacts with checkpoints

Summary:
- Surface tokenizer metadata from dataset loader and copy `tokenizer.json`/`meta.json` beside every saved checkpoint (step, best, final).
- Ensure run directories receive these artifacts immediately and document the new behavior in TRAINING.md.
- Note the update in llm.state for traceability.

Files Touched:
- src/hrm_lm/training/train.py
- TRAINING.md
- llm.state
- .git-commit.txt
- llm.state.bak (local backup, untracked)

Validation:
- python -m compileall src/hrm_lm/training/train.py

Follow-ups:
- Integrate tokenizer awareness into inference CLI (tracked separately).
